{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6289917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ebddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data with specified dtype to avoid mixed-type warning\n",
    "train_data = pd.read_csv(r\"D:\\VSCODE\\venv\\train_splits\\train.csv\", dtype={'handshake_version': str})\n",
    "test_data = pd.read_csv(r\"D:\\VSCODE\\venv\\test_splits\\test.csv\", dtype={'handshake_version': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89730beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Separate features and target\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a562062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Encode target variables\n",
    "le_attack = LabelEncoder()\n",
    "y_train_encoded = le_attack.fit_transform(y_train)\n",
    "y_test_encoded = le_attack.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71112b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify numeric and categorical columns\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "object_cols = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced038a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert categorical columns to strings\n",
    "X_train[object_cols] = X_train[object_cols].astype(str)\n",
    "X_test[object_cols] = X_test[object_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41673587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Encode categorical columns\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_train_object_encoded = encoder.fit_transform(X_train[object_cols])\n",
    "X_test_object_encoded = encoder.transform(X_test[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e011057",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_object_encoded_df = pd.DataFrame(X_train_object_encoded, columns=object_cols, index=X_train.index)\n",
    "X_test_object_encoded_df = pd.DataFrame(X_test_object_encoded, columns=object_cols, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6cd6658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Combine numeric and encoded categorical columns\n",
    "X_train_encoded = pd.concat([X_train[numeric_cols], X_train_object_encoded_df], axis=1)\n",
    "X_test_encoded = pd.concat([X_test[numeric_cols], X_test_object_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da0655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_encoded = pd.DataFrame(imputer.fit_transform(X_train_encoded), columns=X_train_encoded.columns, index=X_train_encoded.index)\n",
    "X_test_encoded = pd.DataFrame(imputer.transform(X_test_encoded), columns=X_test_encoded.columns, index=X_test_encoded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e395a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Scale the features and convert to float32\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded).astype('float32')\n",
    "X_test_scaled = scaler.transform(X_test_encoded).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76993f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Reshape data for LSTM\n",
    "n_features = X_train_scaled.shape[1]\n",
    "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, n_features))\n",
    "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8973fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: One-hot encode target labels\n",
    "num_classes = len(le_attack.classes_)\n",
    "y_train_lstm = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test_lstm = to_categorical(y_test_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe687c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sajid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 12: Define the initial LSTM model with higher dropout to prevent overfitting\n",
    "model_lstm = models.Sequential()\n",
    "model_lstm.add(layers.LSTM(64, input_shape=(1, n_features), return_sequences=False))\n",
    "model_lstm.add(layers.Dropout(0.5))\n",
    "model_lstm.add(layers.Dense(32, activation='relu'))\n",
    "model_lstm.add(layers.Dropout(0.5))\n",
    "model_lstm.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4fd356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 13: Compile the model\n",
    "model_lstm.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d006b627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4ms/step - acc: 0.9806 - loss: 0.0514 - val_acc: 0.9995 - val_loss: 0.0013\n",
      "Epoch 2/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4ms/step - acc: 0.9980 - loss: 0.0066 - val_acc: 0.9994 - val_loss: 0.0013\n",
      "Epoch 3/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4ms/step - acc: 0.9986 - loss: 0.0045 - val_acc: 0.9998 - val_loss: 4.5741e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 4ms/step - acc: 0.9990 - loss: 0.0034 - val_acc: 0.9997 - val_loss: 8.0200e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4ms/step - acc: 0.9991 - loss: 0.0031 - val_acc: 0.9998 - val_loss: 5.4011e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 14: Train the initial model\n",
    "history_lstm = model_lstm.fit(X_train_lstm,\n",
    "                             y_train_lstm,\n",
    "                             epochs=20,\n",
    "                             batch_size=128,\n",
    "                             validation_data=(X_test_lstm, y_test_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0dfd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model - Training Accuracy: 0.9997\n",
      "Initial Model - Test Accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Step 15: Evaluate the initial model on original data\n",
    "train_loss, train_acc = model_lstm.evaluate(X_train_lstm, y_train_lstm, verbose=0)\n",
    "test_loss, test_acc = model_lstm.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "print(f\"Initial Model - Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Initial Model - Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce3a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Convert data to TensorFlow tensors for PGD\n",
    "X_train_tf = tf.constant(X_train_lstm, dtype=tf.float32)\n",
    "X_test_tf = tf.constant(X_test_lstm, dtype=tf.float32)\n",
    "y_train_tf = tf.constant(y_train_lstm, dtype=tf.float32)\n",
    "y_test_tf = tf.constant(y_test_lstm, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97efae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Set PGD parameters\n",
    "epsilon = 0.05  # Maximum perturbation size\n",
    "alpha = 0.005  # Step size per iteration\n",
    "num_iterations = 10  # Number of PGD iterations\n",
    "batch_size = 10000  # Adjust based on available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a739828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 18: Define PGD function for a single batch\n",
    "def apply_pgd_batch(batch_x, batch_y, original_x, model, epsilon, alpha, num_iterations):\n",
    "    adv_x = batch_x\n",
    "    for _ in range(num_iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(adv_x)\n",
    "            predictions = model(adv_x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(batch_y, predictions)\n",
    "        gradient = tape.gradient(loss, adv_x)\n",
    "        perturbation = alpha * tf.sign(gradient)\n",
    "        adv_x = adv_x + perturbation\n",
    "        adv_x = original_x + tf.clip_by_value(adv_x - original_x, -epsilon, epsilon)\n",
    "    return adv_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab7afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 19: Apply PGD to training data in batches\n",
    "num_train_samples = X_train_tf.shape[0]\n",
    "adv_X_train_lstm = []\n",
    "for start_idx in range(0, num_train_samples, batch_size):\n",
    "    end_idx = min(start_idx + batch_size, num_train_samples)\n",
    "    batch_x = X_train_tf[start_idx:end_idx]\n",
    "    batch_y = y_train_tf[start_idx:end_idx]\n",
    "    original_x = X_train_tf[start_idx:end_idx]\n",
    "    adv_batch = apply_pgd_batch(batch_x, batch_y, original_x, model_lstm, epsilon, alpha, num_iterations)\n",
    "    adv_X_train_lstm.append(adv_batch)\n",
    "adv_X_train_lstm = tf.concat(adv_X_train_lstm, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a029fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 20: Apply PGD to test data in batches\n",
    "num_test_samples = X_test_tf.shape[0]\n",
    "adv_X_test_lstm = []\n",
    "for start_idx in range(0, num_test_samples, batch_size):\n",
    "    end_idx = min(start_idx + batch_size, num_test_samples)\n",
    "    batch_x = X_test_tf[start_idx:end_idx]\n",
    "    batch_y = y_test_tf[start_idx:end_idx]\n",
    "    original_x = X_test_tf[start_idx:end_idx]\n",
    "    adv_batch = apply_pgd_batch(batch_x, batch_y, original_x, model_lstm, epsilon, alpha, num_iterations)\n",
    "    adv_X_test_lstm.append(adv_batch)\n",
    "adv_X_test_lstm = tf.concat(adv_X_test_lstm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02da6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 21: Convert adversarial examples back to numpy arrays\n",
    "adv_X_train_lstm = adv_X_train_lstm.numpy()\n",
    "adv_X_test_lstm = adv_X_test_lstm.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7da740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model - Adversarial Test Accuracy: 0.8457\n"
     ]
    }
   ],
   "source": [
    "# Step 22: Evaluate initial model on adversarial test data\n",
    "adv_test_loss, adv_test_acc = model_lstm.evaluate(adv_X_test_lstm, y_test_lstm, verbose=0)\n",
    "print(f\"Initial Model - Adversarial Test Accuracy: {adv_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e2202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 23: Define a new model for adversarial training with the same architecture\n",
    "model_adv = models.Sequential()\n",
    "model_adv.add(layers.LSTM(64, input_shape=(1, n_features), return_sequences=False))\n",
    "model_adv.add(layers.Dropout(0.5))\n",
    "model_adv.add(layers.Dense(32, activation='relu'))\n",
    "model_adv.add(layers.Dropout(0.5))\n",
    "model_adv.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b52e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 24: Compile the adversarial model\n",
    "model_adv.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac5996f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 5ms/step - acc: 0.9923 - loss: 0.0214 - val_acc: 0.9778 - val_loss: 0.1084\n",
      "Epoch 2/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4ms/step - acc: 0.9997 - loss: 9.0602e-04 - val_acc: 0.9761 - val_loss: 0.1203\n",
      "Epoch 3/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - acc: 0.9998 - loss: 5.0764e-04 - val_acc: 0.9774 - val_loss: 0.1625\n",
      "Epoch 4/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4ms/step - acc: 0.9999 - loss: 4.2874e-04 - val_acc: 0.9653 - val_loss: 0.2692\n",
      "Epoch 5/5\n",
      "\u001b[1m16934/16934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4ms/step - acc: 0.9999 - loss: 3.3557e-04 - val_acc: 0.9778 - val_loss: 0.1291\n"
     ]
    }
   ],
   "source": [
    "# Step 25: Train the model on adversarial training data\n",
    "history_adv = model_adv.fit(adv_X_train_lstm,\n",
    "                            y_train_lstm,\n",
    "                            epochs=5,\n",
    "                            batch_size=128,\n",
    "                            validation_data=(X_test_lstm, y_test_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccd2b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarially Trained Model - Training Accuracy: 0.9613\n",
      "Adversarially Trained Model - Test Accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# Step 26: Evaluate the adversarially trained model on original test data\n",
    "train_loss_adv, train_acc_adv = model_adv.evaluate(X_train_lstm, y_train_lstm, verbose=0)\n",
    "test_loss_adv, test_acc_adv = model_adv.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "print(f\"Adversarially Trained Model - Training Accuracy: {train_acc_adv:.4f}\")\n",
    "print(f\"Adversarially Trained Model - Test Accuracy: {test_acc_adv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd8c14db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarially Trained Model - Adversarial Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 27: Evaluate the adversarially trained model on adversarial test data\n",
    "adv_test_loss_adv, adv_test_acc_adv = model_adv.evaluate(adv_X_test_lstm, y_test_lstm, verbose=0)\n",
    "print(f\"Adversarially Trained Model - Adversarial Test Accuracy: {adv_test_acc_adv:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
